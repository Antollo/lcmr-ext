{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from lcmr.grammar import Scene\n",
    "from lcmr.grammar.shapes.shape2d import Shape2D\n",
    "from lcmr_ext.renderer.renderer2d import PyTorch3DRenderer2D\n",
    "from lcmr.utils.presentation import display_img, make_img_grid\n",
    "from lcmr.utils.colors import colors\n",
    "\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "raster_size = (128, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_shape_scene(fourierCoefficients, scale=[0.5, 0.5]):\n",
    "    translation = torch.tensor([[0.5, 0.5]], dtype=torch.float32)[None, None, ...]\n",
    "    color = torch.tensor([[0.2, 0.2, 0.2]], dtype=torch.float32)[None, None, ...]\n",
    "    scale = torch.tensor([scale])[None, None, ...]\n",
    "    confidence = torch.tensor([[0.9]])[None, None, ...]\n",
    "    angle = torch.tensor([[0.0]], dtype=torch.float32)[None, None, ...]\n",
    "    fourierCoefficients = torch.from_numpy(np.array([fourierCoefficients], dtype=np.float32))[None, None, ...]\n",
    "    objectShape = torch.ones(size=(1, 1), dtype=torch.uint8)[None, None, ...] * Shape2D.FOURIER_SHAPE.value\n",
    "\n",
    "    return Scene.from_tensors_sparse(\n",
    "        translation=translation, scale=scale, color=color, confidence=confidence, angle=angle, fourierCoefficients=fourierCoefficients, objectShape=objectShape\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "renderer = PyTorch3DRenderer2D(raster_size, device=device, background_color=colors.white, n_verts=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyefd import elliptic_fourier_descriptors\n",
    "\n",
    "for order in [4, 8, 16, 32]:\n",
    "    print(\"Order:\", order)\n",
    "    fourierCoefficients = elliptic_fourier_descriptors([[0, 0], [0, 1], [1, 1], [1, 0], [0, 0]], order=order)\n",
    "    scene = single_shape_scene(fourierCoefficients)\n",
    "    display_img(renderer.render(scene.to(renderer.device))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "\n",
    "r = sqrt(2) / 2\n",
    "\n",
    "fourierCoefficients = [[r, r, -r, r]] + [[0.0, 0.0, 0.0, 0.0]] * 7\n",
    "scene = single_shape_scene(fourierCoefficients, scale=[0.25, 0.25]).to(device)\n",
    "\n",
    "display_img(renderer.render(scene.to(renderer.device))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio.v3 as iio\n",
    "from torchvision.transforms.functional import resize\n",
    "\n",
    "\n",
    "def resize_img(img):\n",
    "    return resize(img.permute(0, 3, 1, 2), raster_size, antialias=True).permute(0, 2, 3, 1)\n",
    "\n",
    "\n",
    "imgs = [\n",
    "    \"https://img.fruugo.com/product/2/60/557296602_max.jpg\",\n",
    "    \"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcS8Glk9GyCg-xOA1gGan8SM8TkbcaMli-7lQQ&usqp=CAU\",\n",
    "    \"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSoZLVyXxYuVFO68LdjOhQ2Uxmqy0c68aFRG4L29xf93h7Sd8OXWmkgFAKf4Q0kfIvRfQU&usqp=CAU\",\n",
    "    \"https://wheelsauto.com/media/catalog/product/cache/bdfbb51471fa4a0501abac6899ceb6a6/0/5/05094.jpg\",\n",
    "    \"https://i.pinimg.com/736x/07/a5/8b/07a58be0fafc601e8bceef157ae01350.jpg\",\n",
    "    \"https://static8.depositphotos.com/1338574/829/i/950/depositphotos_8292981-stock-photo-the-letter-y-in-gold.jpg\",\n",
    "    \"https://i.etsystatic.com/5709149/r/il/da9a69/3283909570/il_570xN.3283909570_1lnw.jpg\",\n",
    "    \"https://docs.telerik.com/devtools/winforms/telerik-presentation-framework/shapes/images/star-shape001.png\"\n",
    "    \n",
    "]\n",
    "imgs = [resize_img(torch.from_numpy(iio.imread(img)).to(torch.float32)[None, ...] / 255) for img in imgs]\n",
    "imgs = torch.cat(imgs, dim=0)\n",
    "\n",
    "display_img(make_img_grid([imgs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lcmr_ext.utils.optimize_params import optimize_params\n",
    "from lcmr_ext.loss import LPIPSLoss\n",
    "\n",
    "scene_opt = torch.cat([scene] * len(imgs)).to(device)\n",
    "params = [\n",
    "    scene_opt.layer.object.fourierCoefficients,\n",
    "    scene_opt.layer.object.appearance.color,\n",
    "    scene_opt.layer.object.transformation.translation,\n",
    "    scene_opt.layer.object.transformation.angle,\n",
    "    scene_opt.layer.object.transformation.scale,\n",
    "]\n",
    "\n",
    "optimize_params(scene_opt, imgs.to(device), renderer, params=params, show_progress=True, lr=0.001, epochs=2001, show_interval=200, Optimizer=torch.optim.Adam)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
